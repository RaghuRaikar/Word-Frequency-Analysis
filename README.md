ğŸ“– Word Frequency Analyzer
==========================

ğŸ” **Analyze and rank words from any text dataset!**

ğŸ›  Purpose of the Program
-------------------------

This program is designed to analyze large text datasets by identifying **word frequencies** and ranking words based on **length, frequency, and lexicographic order**. Originally built for processing **Shakespeare's works**, it can be applied to **any structured text dataset** where words are stored line by line.

### ğŸ”¹ **Use Cases:**

âœ… **Literary Analysis** -- Identify common themes in classic works like Shakespeare, Dickens, or Austen\
âœ… **Data Processing** -- Extract and rank words from research papers, articles, or books\
âœ… **Linguistic Research** -- Study word frequency distribution and text complexity\
âœ… **Natural Language Processing (NLP) Preprocessing** -- Create structured datasets from raw text

This tool is particularly useful for **students, researchers, linguists, and developers** interested in **text analytics and computational linguistics**.

* * * * *

ğŸ“Œ Features
-----------

âœ… **Custom-built linked list** for efficient word storage & retrieval\
âœ… **Processes any text dataset** with words stored line-by-line\
âœ… **Optimized ranking** based on frequency & lexicographic order\
âœ… **Handles large files** with efficient memory usage\
âœ… **Command-line interface (CLI)** for flexible input/output processing\
âœ… **Makefile included** for easy compilation

* * * * *

ğŸ›  How It Works
---------------

The program reads a **cleaned text file**, where each line contains a **single lowercase word**. It then:\
ğŸ”¹ **Stores words & their frequencies** in a linked list (no built-in lists or arrays)\
ğŸ”¹ **Processes user queries** to find the most frequent words of a given length\
ğŸ”¹ **Outputs results** based on ranking & lexicographic order

* * * * *

ğŸ” Understanding the Input & Output
-----------------------------------

### ğŸ“¥ **Input File (e.g., `simple-input.txt`)**

Each line in the input file contains **two numbers**:\
1ï¸âƒ£ **Word length** -- Filters words of a specific length\
2ï¸âƒ£ **Rank (0-based)** -- Returns the word at that rank based on **frequency & lexicographic order**

ğŸ“Œ **Example Input (`simple-input.txt`):**

`6 3`  
`10 0`  
`9 2`  
`8 14`  
`8 15`  
`26 0`  

* * * * *

### ğŸ“¤ **Output File (e.g., `simple-output.txt`)**

Each line in the output file contains a **single word** matching the input query, or `-` if no word is found.

ğŸ“Œ **Example Output (`simple-output.txt`):**

`father`  
`gloucester`  
`messenger`  
`business`  
`personal`  
`-`  

* * * * *

### ğŸ“Œ **How to Interpret the Output:**

-   **"father"** â†’ The **4th most frequent word** (rank 3) with **6 letters**
-   **"gloucester"** â†’ The **most frequent word** (rank 0) with **10 letters**
-   **"business"** and **"personal"** have the **same frequency**, but **"business"** appears first lexicographically
-   **"-"** â†’ No word exists for that query (e.g., Shakespeare never used a word with 26 letters)

* * * * *

ğŸ”„ Supports Any Dataset
-----------------------

While this program was tested with **Shakespeare's works**, it can analyze **any** dataset formatted as:

`word1
word2
word3
...`

Simply **replace `shakespeare-cleaned5.txt`** with any **cleaned** text dataset.

* * * * *

ğŸš€ Performance & Constraints
----------------------------

âš¡ **Optimized Execution:**

-   Handles **up to 200 queries** in **under 2 minutes**
-   Uses **efficient linked list operations** for quick lookups
-   **Memory-efficient** design for large datasets

ğŸ”¹ **Error Handling:**

-   If no word of the given length exists, it returns `-`
-   If multiple words share the same frequency, they are ranked **alphabetically**

* * * * *

ğŸ“¦ Installation & Usage
-----------------------

### ğŸ“¥ 1. Clone the Repository

`git clone https://github.com/your-repo/word-analyzer.git`  
`cd word-analyzer`

### ğŸ— 2. Build the Program

`make`

This will create an **executable** named `bard`.

### â–¶ï¸ 3. Run the Program

`./bard simple-input.txt simple-output.txt`

ğŸ“Œ **Explanation:**

-   `simple-input.txt` contains **query pairs** (word length & rank).
-   `simple-output.txt` stores the **generated results**.
-   **To use your own dataset**, replace `shakespeare-cleaned5.txt` with a **custom dataset** following the same structure.

* * * * *

ğŸ“‚ File Structure
-----------------

- ğŸ“‚ word-analyzer
- â”œâ”€â”€ ğŸ“„ Makefile               # Automates compilation
- â”œâ”€â”€ ğŸ“„ bard.cpp               # Main program logic
- â”œâ”€â”€ ğŸ“„ linkedlist.cpp         # Custom linked list implementation
- â”œâ”€â”€ ğŸ“„ linkedlist.h           # Linked list header file
- â”œâ”€â”€ ğŸ“„ shakespeare-cleaned5.txt # Cleaned text dataset
- â”œâ”€â”€ ğŸ“„ simple-input.txt       # Sample input queries
- â”œâ”€â”€ ğŸ“„ simple-output.txt      # Generated output
- â”œâ”€â”€ ğŸ“„ README.md              # This file`

* * * * *

ğŸ¯ Algorithm Overview
---------------------

1ï¸âƒ£ **Read and Parse Words**\
2ï¸âƒ£ **Store Words in a Linked List**\
3ï¸âƒ£ **Count Frequencies Efficiently**\
4ï¸âƒ£ **Process Queries in Optimized Order**\
5ï¸âƒ£ **Output Results in Expected Format**

* * * * *

ğŸ“œ Fun Facts from the Shakespeare Dataset!
------------------------------------------

ğŸ­ **Longest Word:** *honorificabilitudinitatibus*\
ğŸ§› **Creepiest Word?** *anthropophaginian* (a cannibal!)\
ğŸ¤´ **"Caesar" appears more than "Brutus"**

* * * * *

ğŸ’¡ Want to Improve It?
----------------------

ğŸ”¹ **Implement trie structures** for even faster lookups\
ğŸ”¹ **Expand beyond Shakespeare** to analyze **other classic texts**\
ğŸ”¹ **Optimize further** with **hashmaps & AVL trees**

* * * * *

ğŸ† Built With
-------------

ğŸ”¹ **C/C++** for efficiency\
ğŸ”¹ **Custom Linked List** (No built-in structures allowed!)\
ğŸ”¹ **Makefile** for seamless compilation
